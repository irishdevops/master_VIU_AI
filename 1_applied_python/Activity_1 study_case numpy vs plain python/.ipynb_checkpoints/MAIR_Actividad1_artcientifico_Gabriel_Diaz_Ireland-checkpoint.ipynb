{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MIAR VIU - Python para la IA - Actividad 1. Lectura de artículos científicos** Gabriel Díaz Ireland\n",
    "\n",
    "\n",
    "Para realizar esta actividad es necesario leer:\n",
    "1. Van Der Walt, S., Colbert, S. C., &amp; Varoquaux, G. (2011). The\n",
    "NumPy array: A structure for efficient numerical computation.\n",
    "Computing in Science and Engineering, 13(2), 22-30.\n",
    "https://www.researchgate.net/publication/224223550_The_NumPy_Array_A_Structure_for_Efficient_Numerical_Computation#:~:text=In%20the%20Python%20world%2C%20NumPy%20arrays%20are%20the,copying%20data%20in%20memory%2C%20and%20minimizing%20operation%20counts.\n",
    "\n",
    "\n",
    "2. McKinney, W. (2010). Data Structures for Statistical Computing in\n",
    "Python. Proceedings of the 9th Python in Science Conference,\n",
    "December, 56-61. https://doi.org/10.25080/majora-92bf1922-00a\n",
    "https://www.researchgate.net/publication/265001241_Data_Structures\n",
    "\n",
    "\n",
    "## Metodología\n",
    "\n",
    "- Crear un notebook de Python que servirá como entrega de la actividad.\n",
    "- Separar bien los apartados propuestos con celdas Markdown.\n",
    "- Mantener una estructura limpia, comentando código y secuenciando los\n",
    "apartados con el código correspondiente que resuelva la actividad.\n",
    "- Como criterio de evaluación se tendrá en cuenta el resultado, la consecución del\n",
    "mismo, estilo, comentarios y adecuación. Siempre será tenido en cuenta cualquier\n",
    "detalle técnico avanzado o no visto en clase relacionado con el tema (explicar el\n",
    "porqué y usabilidad).\n",
    "- No está permitido compartir los resultados ni el código en ninguno de los foros.\n",
    "- Revisar los temas 3 y 4, así como las sesiones sobre Numpy y Pandas para\n",
    "aplicar dichos contenidos.\n",
    "\n",
    "\n",
    "## Pregunta artículo 1\n",
    "\n",
    "En el artículo 1 se presenta la estructura ndarray de NumPy, y se hace un estudio\n",
    "sobre su uso y cómo mejora el rendimiento de ciertas operaciones matemáticas\n",
    "para la computación numérica. Se hace una breve introducción al Broadcasting\n",
    "como técnica que usa NumPy para realizar operaciones aritméticas sobre dos o más\n",
    "arrays con distintas dimensiones:\n",
    "\n",
    "- Pregunta 1 - Ampliar dicha explicación, aportando posibles restricciones o\n",
    "limitaciones a dicho sistema y ejemplos propios de los casos de uso.\n",
    "También se introduce el trabajo con ficheros usando memoria mapeada.\n",
    "\n",
    "- Pregunta 2 - Verificar la eficacia y mejora posible de rendimiento del uso de\n",
    "memoria mapeada sobre ndarrays de tamaños grandes.\n",
    "\n",
    "\n",
    "## Pregunta artículo 2\n",
    "\n",
    "En el artículo 2 el creador de pandas introduce dicha librería en comparación con\n",
    "las estructuras nativas de R.\n",
    "\n",
    "- Pregunta 3 - Desarrollar una opinión razonada del estado actual de las\n",
    "herramientas de análisis de datos estadísticos en contraposición a como se muestran en el artículo, R vs Python vs SQL vs Others.\n",
    "\n",
    "\n",
    "## Objetivo en la realización del trabajo\n",
    "1 - Redacción impecable, con\n",
    "estructura definida, estilo\n",
    "formal y sin faltas\n",
    "ortográficas. Se trabaja con\n",
    "el notebook utilizando\n",
    "estilos, altenando código y\n",
    "comentarios adecuadamete.\n",
    "\n",
    "2 - Se desarrolla correctamente\n",
    "el trabajo sobre los artículos\n",
    "propuestos. Se muestran\n",
    "ejemplos y descripiones de las cuestiones\n",
    "\n",
    "3 - Se incluyen referencias a\n",
    "otros artículos científicos\n",
    "explicando la relación y\n",
    "resumiendo los contenidos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Índice**\n",
    "\n",
    "### Pregunta 1.1\n",
    "  - DESAROLLO - BROADCASTING\n",
    "  - DESAROLLO - MEMORIA MAPEADA\n",
    "  - REFERENCIAS\n",
    "  - CONCLUSIÓN\n",
    "  - TESTING DE BROADCASTING (CÓDIGO PARA EJECUTAR EN PYTHON)\n",
    "  \n",
    "### Pregunta 1.2\n",
    "  - COMENTARIO\n",
    "  - TESTING MEMORIA MAPEADA (CÓDIGO PARA EJECUTAR EN PYTHON)\n",
    "\n",
    "### Pregunta 2.1\n",
    "  - DESAROLLO - CONTENIDO DEL ARTÍCULO\n",
    "  - DESAROLLO - INVESTIGACIÓN DEL ALUMNO\n",
    "  - CONCLUSIÓN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos nuestras librerías\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pregunta 1.1.**\n",
    "## Ampliar la información sobre broadcasting y trabajo de ficheros con memoria mapeada , aportando posibles restricciones o limitaciones a dicho sistema y ejemplos propios de los casos de uso.\n",
    "\n",
    "### DESAROLLO - BROADCASTING\n",
    "\n",
    "En el artículo \"The NumPy array: a structure for efficient\n",
    "numerical computation\" se explica de manera clara, como Numpy tiene mejoras en rendimiento respecto a python como lenguaje en solitario. Tras investigar al respecto, obtenemos las siguiente información sobre el broadcasting en Numpy.\n",
    "\n",
    "Broadcasting es una forma de operar numéricamente en la que si los arrays no tiene la misma dimensión y se cumple que, el array más pequeño se pueda duplicar varias veces para rellenar hasta alcanzar la dimensión del array más grande, se realizarán las operaciones extendiendo dicho array pequeño . Las reglas para poder expandir este array nos llevan a las asignaturas de cálculo II de la carrera, donde nos enseñaban operaciones entre matrices. Si la matriz que hacemos broadcast (Matriz A) tiene el mismo número de columnas que columnas la matriz B, entonces podremos hacer el broadcast de dicha matriz A sobre B, aunque siempre la matriz A (o la que sea más pequeña) tendrá dimensión uno. [1]\n",
    "\n",
    "Ejemplo sencillo con matriz (arrays) de dimensión 1 \n",
    "\n",
    "   Array_A = np.array([1,2,3,4])\n",
    "   Array_B = np.array([2])\n",
    "\n",
    "   out = Array_A * Array_B  #[1,2,3,4]  * [2,2,2,2] ## Esta es la multiplicación que está ocurriendo el valor final será [2.4.6.8], por que se hace broadcast de Array_B\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "¿Y cuales son los beneficios de esto a la hora de ejecutar código?\n",
    "\n",
    "\n",
    "\n",
    "Como bien explica el artículo que estamos analizando, NumPy guarda sus arrays en un bloque de memoria, donde tenemos elementos como el \"Data pointer\" que encuentra dónde está ese bloque, o el \"Stride\" que nos dice cuántos bytes hay que moverse en la memoria para llegar a determinado lugar  dentro de ese array, siendo más fácil de localizar la columna o fila necesaria sin tener que iterar por todos y cada uno de los elementos [0].\n",
    "\n",
    "Esto es posible gracias a que NumPy utiliza código escrito en C y Fortran, optimizado para cálculos numéricos. El código subyacente está muy ajustado y aprovecha las optimizaciones de bajo nivel, como el desenrollado de bucles y las instrucciones SIMD (Single Instruction, Multiple Data), para procesar los elementos de la matriz de forma eficiente. Esto es gracias a la capacidad del intel del ordenador. Algunos ejemplos que se exponen en la documentación oficial de python son Intel's SSE and AVX y AMD's XOP [2].\n",
    "\n",
    "SIMD es una técnica informática que permite manejar varios datos al mismo tiempo. Son las siglas de \"Single Instruction Multiple Data\". Esto es por que la misma instrucción se aplica a varios elementos de datos en paralelo. Esto permite al procesador trabajar con varios elementos de datos al mismo tiempo, lo que aumenta el rendimiento del programa [3]. Con NumPy se aprovecha esta técnica para realizar operaciones entre los arrays, de manera que si por ejemplo multiplicamos un array por otro, la función que multiplica filas y columnas de manera correspondiente se reproduce varias veces, aumentando la velocidad enormemente.\n",
    "\n",
    "Para acabar, mencionar también que gracias al broadcasting, evitamos tener que replicar y guardar grandes arrays en la memoria, ya que podemos multiplicar ese vector (array de dimensión 1) duplicando en el momento en el que se realiza la operación y no guardándolo en la memoria.\n",
    "\n",
    "Resumiendo mucho estos últimos apartados en 2 apartados claros, podemos concretar que los beneficios del broadcasting son:\n",
    "\n",
    " 1- Mejora en el uso de memoria al no tener que guardar arrays enormes o vectores enormes para realizar cálculos.\n",
    "\n",
    " 2- Mejora en la velocidad de procesado de la función (Gracias a C, Fortran y la arquitectura SIMD)\n",
    "\n",
    "### DESARROLLO - MEMORIA MAPEADA\n",
    "\n",
    "En el artículo se menciona el uso de la memoria mapeada cómo técnica de NumPy para guardar arrays. En el proceso de memoria mapeada, se usa una memoria virtual en la que se guarda la referencia a un objeto en el disco duro. La memoria virtual se suele corresponder a una porción de la RAM (kernel) en la que se guardan dichos mapeos y referencias  en el disco duro. De esta manera, el sistema consigue tener una \"mayor memoria falsa\", ya que cuando se quiera acceder otro archivo, puede cambiar la referencia de entrada desde la RAM directamente y operar sobre el archivo en el disco duro a partir de las instrucciones en la RAM, extrayendo la parte necesaria del array en cada momento [4].\n",
    "\n",
    "En nuestro caso, se utiliza la función class numpy.memmap(filename, dtype=<class 'numpy.ubyte'>, mode='r+', offset=0, shape=None, order='C'), que cuenta cpn varios modos de uso (mode{‘r+’, ‘r’, ‘w+’, ‘c’}) en los que cada tipo de mapeo permite al usuario volver a llamar y editar el array, o solo visualizarlos, etc... El estándar es r+ (Edición y lectura) [5].\n",
    "\n",
    "Gracias a esta breve explicación, podemos llegar a la conclusión de cuales son las ventajas de usar memoria mapeada en nuestro ordenador.\n",
    "\n",
    "- Se puede trabajar con una memoria mayo que la física disponible en la RAM, teniendo en la RAM \"cabeceras\" del objeto original y transformando el objeto entero por partes gracias a la memoria virtual. De esta manera, podemos llamar por \"indexation\" a las distintas partes de la memoria \"Data Pointers\" que conforman el objeto.\n",
    "- Se puede fácilmente guardar los cambios de los datos y se guarda de una manera eficiente y comprimida en formato .npy.\n",
    "\n",
    "\n",
    "\n",
    "### REFERENCIAS\n",
    "\n",
    "[0] -> https://www.researchgate.net/publication/224223550_The_NumPy_Array_A_Structure_for_Efficient_Numerical_Computation#:~:text=In%20the%20Python%20world%2C%20NumPy%20arrays%20are%20the,copying%20data%20in%20memory%2C%20and%20minimizing%20operation%20counts\n",
    "[1] -> https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "[2] -> https://ipython-books.github.io/45-understanding-the-internals-of-numpy-to-avoid-unnecessary-array-copying/#:~:text=A%20NumPy%20array%20is%20basically%20described%20by%20metadata,block%20of%20memory%20is%20called%20the%20data%20buffer.\n",
    "[3] -> https://lovtechnology.com/en/what-is-simd-single-instruction-multiple-data-how-does-it-work-and-what-is-it-forimage-source-freeimagessimd-or-single-instruction-multiple-data-is-a-powerful-information-technique/\n",
    "[4] -> https://youtu.be/8hVLcyBkSXY\n",
    "[5] -> https://numpy.org/doc/stable/reference/generated/numpy.memmap.html#numpy.memmap\n",
    "\n",
    "### CONCLUSIÓN\n",
    "\n",
    "- Respecto a el rendimiento de NumPy y el broadcasting: el alumno pensaba que cualquier librería empeoraba el rendimiento de un código creado desde python. Ahora se da cuenta de que esto no es así y que merece la pena utilizar NumPy, y entiende ahora de dónde viene la fama de NumPy como biblioteca para hacer operaciones numéricas. En ese aspecto, le da las gracias al profesor por enseñarlo en clase y con este ejercicio.\n",
    "\n",
    "- Respecto a la memoria mapeada: Realizar el ejercicio de buscar e investigar que es la memoria mapeada, que es una memoria virtual y como funcionan \"las páginas\" de dicha memoria virtual (Referencia [4])(Junto a más cosas que han ido saliendo, como una revisión del tema de magnetismo y grabado de bytes en las memorias existentes), y como esto da beneficio por parte de Numpy a manejar grandes sets de datos ha sido muy útil para acercarse a entender cada vez mejor, como funciona un ordenador y como funciona python. \n",
    "\n",
    "- Funciones destacadas y que han llamado la atención del alumno:\n",
    "\n",
    "  Memoria mapeada\n",
    "   A =  np.memmap(’/tmp/myarray.memmap’,\n",
    "...: mode=’write’, shape=(300, 300),\n",
    "...: dtype=np.int)### Crea la memoria mapeada\n",
    "\n",
    "   A.flat = np.arange(300* 300)## Asigna valores (ID) a cada matriz de un array de más de una dimension, para tratarla como un array de dimensión 1\n",
    "\n",
    "   A.flush() ## Guarda en la memoria cualquier cambio realizado. Esto ya se guarda en el disco duro y afecta a todo el array del disco duro.\n",
    "\n",
    "\n",
    "   Moverse por el array\n",
    "\n",
    "   y = x[::2, ::2] ## Aquí lo que se hace es pillar un item cada dos item para tanto las filas como para las columnas\n",
    "\n",
    "   Mirar el lugar de la memoria (bytes) donde se encuentra nuestro objeto numpy\n",
    "\n",
    "         arr = np.array([6, 654], dtype=np.uint16)\n",
    "\n",
    "         data_pointer = arr.data\n",
    "\n",
    "         print(data_pointer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TESTING DE BROADCASTING (CÓDIGO PARA EJECUTAR EN PYTHON)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[15  2 11]\n",
      "  [15  2 11]]\n",
      "\n",
      " [[ 9  3  9]\n",
      "  [ 9  3  9]]]\n",
      " \n",
      "For second operation - operands could not be broadcast together with shapes (4,) (2,) \n",
      " \n",
      "Test 1. Tiempo de ejecución con NumPy: 0.49442553520202637\n",
      "Test 2. Tiempo de ejecución con función de Python: 52.1525182723999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Ejemplo de broadcasting correcto en el que se hace broadcasting de una matriz de dimensión 2 (B2) con una de dimensión 1 (A1)\n",
    "\n",
    "Array_A1 = np.array([8,1,6])\n",
    "Array_B2 = np.array([[[7,1,5],[7,1,5]],[[1,2,3],[1,2,3]]])\n",
    "print(Array_A1 + Array_B2 )\n",
    "\n",
    "#Ejemplo de error de broadcasting incorrecto\n",
    "\n",
    "try:\n",
    "  Array_A = np.array([1,2,3,4])\n",
    "  Array_B = np.array([2,2])\n",
    "  Array_A * Array_B\n",
    "except Exception as e:\n",
    "  print(\" \")\n",
    "  print(\"For second operation - \" + str(e))\n",
    "\n",
    "#Test sin hacer Broadcasting (Hacemos los test de velocidad que hemos explicado antes)\n",
    "\n",
    "\n",
    "arrayXL = np.ones((10000, 10000)) #Array de dimensión 2 rellena de 1 (Si fuera dimension 3 sería np.ones((10000, 10000, 10000)) ) y así sucesivamente con mas dimensione.\n",
    "\n",
    "\n",
    "start_time_np = time.time()\n",
    "result_np = arrayXL + 5\n",
    "end_time_np = time.time()\n",
    "\n",
    "# Test usando broadcasting\n",
    "\n",
    "start_time_py = time.time()\n",
    "result_py = [[element + 5 for element in row] for row in arrayXL]\n",
    "end_time_py = time.time()\n",
    "\n",
    "# Resultados\n",
    "print(\" \")\n",
    "print(\"Test 1. Tiempo de ejecución con NumPy:\", end_time_np - start_time_np) # APROXIMADAMENTE 1 segundo\n",
    "\n",
    "print(\"Test 2. Tiempo de ejecución con función de Python:\", end_time_py - start_time_py) ### APROXIMADAMENTE 38 segundos\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pregunta 1.2.**\n",
    "\n",
    "# Verificar la eficacia y mejora posible de rendimiento del uso de memoria mapeada sobre ndarrays de tamaños grandes.\n",
    "\n",
    "### Comentario\n",
    "\n",
    "Nótese que ya se hace la investigación y confusión sobre memoria mapeada en el apartado 1.1.\n",
    "\n",
    "En consecuencia procedemos a realizar el test directamente\n",
    "\n",
    "\n",
    "### Testing de Memoria Mapeada (Código para ejecutar en python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución con memoria mapeada: 0.33239221572875977 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\díazirg\\AppData\\Local\\Temp\\1\\ipykernel_1672\\2952021509.py:23: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result_normal = np.sqrt(normal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución con memoria convencional: 0.8733458518981934 segundos\n",
      "La memoria mapeada ofrece una mejora de rendimiento.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creamos un Array grande con la misma metolodía que se usa en el archivo\n",
    "\n",
    "filename = ##\"INSERTAR AQUÍ RUTA PARA CORRER MEMORIA MAPEADA\"\n",
    "\n",
    "# Creamos el archivo de memoria mapeada\n",
    "memmapeada = np.memmap(filename, np.float32, mode='w+', shape= (10000, 10000)) #10000 columnas * 100000 columnas (Array de dos dimensiones)\n",
    "\n",
    "# Llenamos Array con valores aleatorios\n",
    "memmapeada[:] = np.abs(np.random.randn(*shape)) ##Nos cercionamos de que los valores del array seán  positivos para que no den problemas con la operación que realizamos (sqrt)\n",
    "\n",
    "\n",
    "start_time_memmap = time.time() # Test Memoria Mapeada\n",
    "result_memmap = np.sqrt(memmapeada) # Test Memoria Mapeada\n",
    "end_time_memmap = time.time() # Test Memoria Mapeada\n",
    "execution_time_memmap = end_time_memmap - start_time_memmap # Test Memoria Mapeada\n",
    "print(f\"Tiempo de ejecución con memoria mapeada: {execution_time_memmap} segundos\")\n",
    "\n",
    "# Cremos archivo con memoria (Solo RAM)\n",
    "normal = np.random.randn(*shape)\n",
    "\n",
    "\n",
    "start_time_normal = time.time() # Test Memoria RAM\n",
    "result_normal = np.sqrt(normal) # Test Memoria RAM\n",
    "end_time_normal = time.time()# Test Memoria RAM\n",
    "execution_time_normal = end_time_normal - start_time_normal\n",
    "print(f\"Tiempo de ejecución con memoria convencional: {execution_time_normal} segundos\")\n",
    "\n",
    "# El resultado generado con la ejecución del alumno es de 0,8 segundos a 0,4 segundos siendo la primera la memoria convencional y la segunda (El doble de rápido) la memoria mapeada.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMENTARIOS\n",
    "\n",
    "Nos damos cuenta:\n",
    "\n",
    " - No podemos guardar dos veces el mismo archivo de memoria mapeada, ya que una que se usa \"flush\" para guardarla (Mirar explicación en punto 1.1), ese \"path\" queda asignado a ese array.\n",
    " - No tiene sentido volver a cargar una memoria mapeada, ya que se queda en nuestra memoria virtual mientras que tengamos la RAM funcionando.\n",
    "\n",
    " - En el ordenador de empresa, no se pueden realizar acciones de guardado de .np en el usuario pero si se pueden guardar .csv con data mining desde la nube (tras probarlo con los datos de USA vistos en clase). Esto, por lo que he podido leer, se debe mayoritariamente  a que los archivos binarios son más complicados de manejar y descodiicar pos sistemas de seguridad, y por eso puede haber restricciones al respecto.\n",
    "\n",
    " - RESULTADOS: Cuando el alumno corre el test realizando las operaciones de realización de cuadrados, observa una mejora de ejecución de 0,8 segundos a 0,4 segundos siendo la primera la memoria convencional y la segunda (El doble de rápido) la memoria mapeada.\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pregunta 2.1.**\n",
    "\n",
    "# Desarrollar una opinión razonada del estado actual de las herramientas de análisis de datos estadísticos en contraposición a como se muestran en el artículo, R vs Python vs SQL vs Others.\n",
    "\n",
    "### Desarrollo - Contenido del Artículo\n",
    "\n",
    "Para realizar la contraposición al artículo \"Data Structures for Statistical Computing in Python\", necesitamos resumir primero los puntos más importantes.\n",
    "\n",
    "El primer aspecto a tener en cuenta, es que este artículo científico fue publicado en 2010, hace 13 años. Durante este periodo de tiempo, el mercado digital puede haber cambiado considerablemente y será un aspecto a tener en cuenta a la hora de realizar la investigación por parte del alumno.\n",
    "\n",
    "Los puntos claves del artículo son los siguientes:\n",
    " - Rendimiento de la librería pandas, en comparación con las herramientas disponibles del mercado en el momento.\n",
    " - Comparación del DataFrame de Pandas vs Rstudio (La conclusión es que ambos son muy similares)(Otro punto interesante es que los formatos de datos a la hora de trabajar con estadística suelen ser tabulares)\n",
    " - Se menciona como la aplicación de numpy.isnan  permite detectar los valores NaN para posteriormente reemplazarlos. Pandas tiene funciones API especiales (isnull y notnull) para determinar la validez de un punto de datos. Se contrasta con con numpy.isnan en que pueden usarse con dtypes distintos de float y también detectan algunos otros marcadores parecidos a NaN. \n",
    " - Se comenta la preferencia de uso de NumPY \"MaskedArrays\" VS NaN (Y se llega a la conclusión de que NaN es preferible por que tiene una mayor trazabilidad)\n",
    " - El uso de modelos estadísticos con Pandas requiere de menos preparación de datos que en otros lenguajes (Como puede ser Rstudio)\n",
    " - Por último, remarcar el uso de los formatos de fechas (DateTime) automático en pandas, en el que al darle el tipo de dato al índice, ya tenemos en cuenta una transformación automática de los datos. Esto tiene su contraparte, ya que dado que pandas utiliza el objeto datetime incorporado directamente de python, se podrían prever problemas de rendimiento con conjuntos de datos de series temporales muy grandes o de alta frecuencia. Para la mayoría de las aplicaciones generales no podemos justificar complicar datetime\n",
    "\n",
    "\n",
    "\n",
    "### Desarrollo - Investigación del alumno\n",
    "\n",
    "Pandas (Publicada en 2008) es una librería intuitiva y utilizada a nivel global para el análisis de datos para operaciones con datos pre-estructurados. Está construida en parte sobre NumPy (Publicada en 2005). Pandas, como bien menciona el artículo, permite trabajar mejor sobre datos tabulados, aunque a la larga esta librería que también es más fácil de usar para el usuario, tiene menor eficiencia en temas de memoria y rendimiento que NumPy [1]. Aún así, en muchas industrias se decide usar Pandas por su mayor capacidad de procesamiento, sobre todo cuando hay más de 500k de filas en el dataset y cuando queremos trabajar con datos tabulares (Si se quieren hacer operaciones numéricas es mejor usar NumPy).\n",
    "\n",
    "El artículo también hace referencia y compara pandas con R, dejando claro que tiene partes de similitud (La manera de trabajar con los DataFrame). La mayor diferencia que nota el alumno entre pandas y R (Por experiencia personal) es que R es una plataforma de análisis estadístico integrado en un único lenguaje, esto hace que la necesidad de llamar paquetes sea mucho menor que con pandas. Por otro lado, pandas y python permiten realizar una combinación de un mayor número de librerías y funcionalidades que quizá no encontremos en Rstudio. Este último apartado también se contratasta en otras fuentes [2]\n",
    "\n",
    "En contraposición a la manera que comparan Rstudio y pandas en el artículo, nosotros podemos dar otro punto de vista:\n",
    "\n",
    "Rstudio - Pensado para análisis estadístico en estudios y con objeto de sacar reportes y gráficas sin necesidad de importar varios paquetes. Desde la experiencia personal, con Rstudio (La plataforma de desarrollo) tiene mejor experiencia de usuario que Pandas\n",
    "\n",
    "Pandas - Siempre se podrá combinar con más librerías de python. Además, python es un lenguaje más integrado y común que R, facilitando el desarollo a cualquier desarrollador que tenga que leer el código dentro de la empresa en la que se trabaja. También, suele ser más eficiente que Rstudio al estar construido sobre NumPy (Que a su vez como hemos visto en las preguntas anteriores, usa C y Fortran optimizado)\n",
    "\n",
    "En consecuencia podemos decir que tanto Rstudio como Pandas son métodos válidos para realizar análisis estadístico y que NumPy se usa para operaciones numéricas grandes. Tanto Rstudio como Pandas pueden transaccionar grandes cantidades de datos, pero ¿cuáles son los mejores modelos actuales para datos masivos?\n",
    "\n",
    "Aquí es donde entra en juego Apache Spark (Librería PySpark para python). Apache Spark es un framework de computación distribuida y procesamiento de datos en tiempo real. Está diseñado para procesar grandes volúmenes de datos de manera eficiente y escalable. El lenguaje base de Apache Spark es Scala, PySpark es la librería de python que se adapta al FrameWork de Apace Spark y que permite trabajar con python en ApacheSpark [3]. \n",
    "\n",
    "La ventaja principal de Apache Spark es que puede correr datos en clúster y de manera paralela, procesando a una velocidad mucho mayor los datos y siendo la mejor herramienta para Big Data, esto es por que no solo admite operaciones de \"map\" y \"reduce\", sino también algoritmos de aprendizaje automático (ML),  consultas SQL, entre otros. Spark utiliza la memoria RAM para la computación, lo que agiliza el procesamiento. También ofrece 80 operadores de alto nivel para desarrollar aplicaciones paralelas [4].\n",
    "\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "- El alumno no conocía bien como funcionaba Apache Spark y ha tomado ventaja del enunciado \"opinión razonada del estado actual de las herramientas de análisis de datos estadísticos en contraposición a como se muestran en el artículo, R vs Python vs SQL vs Others\" para enterarse bien de que es y como funciona\n",
    "\n",
    "- Tanto Rstudio como Pandas son buenas opciones para set de datos grandes, pero no la mejor opción para set de datos de big data y análisis en la nube. Además, Pandas utiliza solo un núcleo de procesamiento normalmente (Se puede complementar con los procesamientos vectorizados y broadcasting de NumPy revisados en la pregunta 1.1). Pese a que los scripts se puedan ejecutar en la nube y con sets de datos grandes, no es lo más óptimo para procesar set en la nube ya que pandas está pensado para correr en un solo ordenador.\n",
    "\n",
    "- También mencionamos la experiencia de Rstudio vs python y pandas, en la que para análisis estadísticos y estudios desde el unto de vista del alumno (Hay que escribir menos código y las herramientas de visualización van integradas) es mejor Rstudio. Aunque pandas sea más eficiente por estar construido sobre NumPy\n",
    "\n",
    "- Como conclusión final, PySpark es la mejor opción para análisis estadísticos a grande escala. Usando la API y un framework de Apache Spark podemos integrar python y correr procesos paralelos dentro del propio script.\n",
    "\n",
    "\n",
    "\n",
    "### Referencias\n",
    "\n",
    "[1] https://www.geeksforgeeks.org/difference-between-pandas-vs-numpy/\n",
    "[2] https://www.dataquest.io/blog/python-vs-r/\n",
    "[3] https://www.geeksforgeeks.org/pyspark-vs-python/\n",
    "[4] https://www.geeksforgeeks.org/difference-between-spark-dataframe-and-pandas-dataframe/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
